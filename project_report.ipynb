{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0848637-35c5-4773-b9cd-3cc219a8235e",
   "metadata": {},
   "source": [
    "<font size = \"6\">**Group Project Report**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4311ee-bd52-4d6a-a297-8ec3b9b72cd5",
   "metadata": {},
   "source": [
    "**Using common risk factors to predict Heart Disease-the effect of age, serum cholesterol level, and resting blood pressure on disease diagnosis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dd721-2c87-48e6-b5e6-2834f1a11921",
   "metadata": {},
   "source": [
    "**Jacob Wang, Steven Suo, Jiamin Li, Athena Song**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69810f6-466b-4e1e-bfdd-8437a4e9badd",
   "metadata": {},
   "source": [
    "<font size = \"5\"> Introduction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7ded9-a46e-4bc9-9a1d-fc33b6b40a93",
   "metadata": {},
   "source": [
    "Heart disease(HD) can be described as any health condition that affects the heart, and it is often fatal if not treated at earlier stages. It can be diagnosed by many risk factors. Therefore, developing methods of the identification of HD based on the risk factors has become a top priority. This project is to develop a model based on the Cleveland dataset that could effectively identify HD based on three risk factors: age, serum cholesterol level, and resting blood pressure. This dataset includes both common risk factors and a number that represent disease status, with 0 being healthy and 1, 2, 3, or 4 being increasing disease stages. This dataset contains 14 attributes (columns) in total, and 303 records for each attribute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8e633-3e24-48cf-8c75-39574be81476",
   "metadata": {},
   "source": [
    "We are using the Cleveland dataset from the Heart Disease Database to preduct if a patient from Cleveland will have heart disease. The data set has the following variables and columns:\n",
    "\n",
    "1. age: Age\n",
    "2. sex: sex \n",
    "3. cp: chest pain type\n",
    "4. trestbps: resting blood pressure in mmHg\n",
    "5. chol: serum cholestoral in mg/dl\n",
    "6. fbs: fasting blood sugar \n",
    "7. restecg: resting electrocardiographic results\n",
    "8. thalach: maximum heart rate\n",
    "9. exang: whether exercise induced angina\n",
    "10. oldpeak: ST depression induced by exercse, relative to rest\n",
    "11. slope: slope of peak exercise ST segment\n",
    "12. ca: number of major vessels\n",
    "13. thal: 3 being normal, 6 being fixed defect, 7 being reversable defect\n",
    "14. num: diagnosis of heart disease, 0 is none, 1-4 is severity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afd3ef-3932-4cf4-8378-ec222d81343b",
   "metadata": {},
   "source": [
    "<font size = \"5\"> Methods </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557093a3-4be2-4ec6-a1c5-05d3aba8ba15",
   "metadata": {},
   "source": [
    "**Loading, Wrangling, Summarizing, and Splitting the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2acf77-65e5-4c5e-8ef4-0cd9d18811e6",
   "metadata": {},
   "source": [
    "1. We first imported libraries and then loaded cleveland dataset from the internet using read_csv.\n",
    "2. Cleaned and tidied the data to make it usable by naming the columns, filling in the ? for NA and adding a new column (diagnosis).\n",
    "3. Split Data into a training and a testing set to set up a dataset to build our predictor and one for testing it.\n",
    "4. Grouped and summarized the training set to make a prediction based on the means of our predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1dcda-d20a-4202-a12c-585c376536c3",
   "metadata": {},
   "source": [
    "**Visualizing our Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009dd1f-0ce9-4b1a-ba27-9416c266da94",
   "metadata": {},
   "source": [
    "We visualized the relationship between age, cholesterol, and resting heart rate to get a deeper understanding of how these variables predict a diagnosis. We plotted every variable against another one and used diagnosis to color in the points. Based on our visualization, we could conclude that patient diagnosed with heart disease tend to have a higher age, higher cholesterol, and higher resting blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cce6b-a320-419c-aaf5-cd9f98181138",
   "metadata": {},
   "source": [
    "**Fitting the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d724c79-f1bb-485f-9e76-6f056c68d9ce",
   "metadata": {},
   "source": [
    "We also wanted to find the best value for the knn classification, which would give the highest accuracy. We create a classifier and perform cross-validation to split the training data, train the model wth one set and use the other to evaluate it. We first used the recipe function to center and scale the data and then performed cross-validation with ten folds using vfold_cv on the training data. We used 10 folds because it would increase out accuracy because if we only split it once, the results strongly depend on one split. Next, we created a k-nearest model to find the best value of k for the k-nearest classification. We add the recipe and model to a workflow and by using tune_grid to fit. Then we found the best k value by filtering for accuracy and plotting a line plot with accuracy estimate on the y-axis and k neighbors on the x-axis giving us a specific k value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88a18c-3fce-4c9a-bb6c-667d22ee111c",
   "metadata": {},
   "source": [
    "**Testing the Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced2846-9c16-4913-8c8c-218970a3eb12",
   "metadata": {},
   "source": [
    "To test out classifier we made a new model specification for the best k value chosen and then applied the recipe made earlier in a workflow and fit the classifier to our training set. Then we used predict on the testing set to evaluate the classifier's prediction accuracy on our testing data set. Finally we took metrics and made a confusion matrix to check the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850c939-936d-405b-843d-67f3751a2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(RColorBrewer)\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca411fc-e8f8-458e-a14f-fe1136cde90a",
   "metadata": {},
   "source": [
    "Importing the Cleveland Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6c3d3-841c-4819-85d5-85c8ec2974bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "cleveland_data <- read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",\n",
    "                           col_names = c(\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "                                         \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"))\n",
    "head(cleveland_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc85615-72f4-48ae-93f9-7b819f93805f",
   "metadata": {},
   "source": [
    "*table 1*\n",
    "\n",
    "**Tidying and Wrangling the Data**\n",
    "\n",
    "We need to first change the \"?\",  to NA so their columns can be assigned the types that we need. The original dataset likely had \"?\" for unknown values, so we use NA instead. \n",
    "\n",
    "We will also create a new column to help in our analysis called \"diagnosis\". The original data has a column called \"num\", which classified the severity of heart disease (from 0-4, with 0 meaning none and 4 meaning high severity). The \"diagnosis\" column could help us identify heart disease easier regardless of severity. The point of our data analysis is to determine whether or not THINGS can predict heart disease so the severity is not really that important. We mainly just want to know if a patient has it (1,2,3) or does not have it (0). It also is good to have a diagnosis column in general because it's a lot easier to just identitfy which patients have heart disease with a simple \"they either have it, or they don't\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559ee67-b945-4ea7-ac25-2dedee703f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "# cleaning, wrangling data\n",
    "\n",
    "#Chainging all of the \"?\" to NA so we can clean the data easier\n",
    "cleveland_tidy <- cleveland_data\n",
    "cleveland_tidy [cleveland_tidy == \"?\" ] <- NA\n",
    "\n",
    "cleveland_tidy <- mutate(cleveland_tidy, diagnosis = as.factor(ifelse(is.na(num), NA, (num > 0)))) |>\n",
    "                    mutate(sex = as.factor(sex), cp = as.factor(cp), \n",
    "                           fbs = as.factor(fbs), restecg = as.factor(restecg),\n",
    "                           exang = as.factor(exang), thal = as.factor(thal),\n",
    "                           ca = as.factor(ca), slope = as.factor(slope))\n",
    "head(cleveland_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32159837-f0cf-4c50-bfd5-b8d55c25102b",
   "metadata": {},
   "source": [
    "*table 2*\n",
    "\n",
    "**Creating a Training and a Testing Set**\n",
    "\n",
    "We want to predict our \"diagnosis\" by stratifying it. We will split our data frame into 75% training and 25% testing. This will allow us train our model with 75% of the data frame and also keep 25% of the data frame to test our set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f20687-682b-4e25-a314-d72d70b10b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "cleveland_split <- initial_split(cleveland_tidy, prop = 0.75, strata = diagnosis)\n",
    "\n",
    "cleveland_training <- training(cleveland_split)\n",
    "cleveland_testing <- testing(cleveland_split)\n",
    "\n",
    "head(cleveland_training)\n",
    "nrow(cleveland_training)\n",
    "head(cleveland_testing)\n",
    "nrow(cleveland_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8b380-7533-4320-966f-d47054c5f0c3",
   "metadata": {},
   "source": [
    "*table 3*\n",
    "*table 4*\n",
    "\n",
    "There are 227 rows (75%) in our cleveland_training and 76 rows (25%) in our cleveland_testing. As mentioned above, this gives a really good proportion of data to test our classifier and also enough data to test the classifier later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d72d4-91e4-41c5-997b-ed9806dbef29",
   "metadata": {},
   "source": [
    "**Grouping and Summarizing the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94ae16-ea26-4162-9780-7a32e0e7bd87",
   "metadata": {},
   "source": [
    "We will now use group_by and summarize to find the mean of our predictors for different diagnoses. We do this to find out if there is a noticeable difference between age, cholesterol, and resting blood pressure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbbd89-3cd3-42c6-8ba9-a2e2199ee501",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "cleveland_summary <- cleveland_training |> \n",
    "    group_by(diagnosis) |> \n",
    "    summarize(mean_age = mean(age), \n",
    "              mean_chol = mean(chol), \n",
    "              mean_trestbps = mean(trestbps),\n",
    "              num_patients = n())\n",
    "cleveland_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3507c5-54e1-4763-8e4e-4e0deb249efd",
   "metadata": {},
   "source": [
    "*table 5*\n",
    "\n",
    "We can see that patients with heart disease tend to have higher cholesterol, higher resting blood pressure, and higher age. These are what we expect our classifier to predict later on. Our classifier is also fair and unbiased because as we can see in the num_patients column, we have around the same amount of TRUE and FALSE, 104 and 123 respectfully. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fab0ad-2bab-4bc7-8ad7-8373b4d21864",
   "metadata": {},
   "source": [
    "**Visualizing the Predictors and Diagnosis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9aaf0-8c9d-428e-9002-ea2409a8a0ab",
   "metadata": {},
   "source": [
    "We will use a scatter plot with ggplot of different predictors to try and visualize the relatinoship between age, cholesterol, and resting blood pressure to a patient's diagnosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d650b-26d1-4469-8f3a-d409ed54acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data: \n",
    "age_vs_chol_plot <- ggplot(cleveland_training, aes(x = chol, y = age, color = diagnosis)) + \n",
    "    geom_point() + \n",
    "    labs(x = \"Serum Cholesterol (mg/dl)\", y = \"Age of Patient\", color = \"Diagnosis\") + \n",
    "    ggtitle(\"Serum Cholesterol vs Age of Patient\") + \n",
    "    scale_color_brewer(palette = \"Set1\")\n",
    "age_vs_chol_plot\n",
    "\n",
    "trestbps_vs_chol_plot <- ggplot(cleveland_training, aes(x = chol, y = trestbps, color = diagnosis)) + \n",
    "    geom_point() + \n",
    "    labs(x = \"Serum Cholesterol\", y = \"Resting Blood Pressure (mmHg)\", color = \"Diagnosis\") + \n",
    "    ggtitle(\"Serum Cholesterol vs Resting Blood Pressure\") + \n",
    "    scale_color_brewer(palette = \"Set1\")\n",
    "trestbps_vs_chol_plot\n",
    "\n",
    "age_vs_trestbps_plot <- ggplot(cleveland_training, aes(x = age, y = trestbps, color = diagnosis)) + \n",
    "    geom_point() + \n",
    "    labs(x = \"Age of Patient\", y = \"Resting Blood Pressure (mmHg)\", color = \"Diagnosis\") + \n",
    "    ggtitle(\"Age of Patient vs Resting Blood Pressure\") + \n",
    "    scale_color_brewer(palette = \"Set1\")\n",
    "age_vs_trestbps_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be72814-4a5d-4868-a259-422488730b75",
   "metadata": {},
   "source": [
    "*figure 1, figure 2, figure 3*\n",
    "\n",
    "These graphs show that patients diagnosed with heart disease (blue points TRUE diagnosis) tend to have a higher age, higher cholesterol, and higher resting blood pressure. It also shows that patients without heart disease are the inverse, with lower age, lower cholesterol, and lower resting blood pressure. This visualization confirms what we have in our summary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc579d7e-2283-4f74-b328-c85f9764ab58",
   "metadata": {},
   "source": [
    "**Tuning and KNN Results**\n",
    "\n",
    "We want to find the best k value and tune our predictor. We first create a recipe, then make a k nearest neighbors specification to perform cross-validation. Next create a workflow combining with tune_grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15c883-3bd2-4f14-9ed0-17a0c9158883",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "cleveland_recipe <- recipe(diagnosis ~ chol + age + trestbps, data = cleveland_training) |> \n",
    "    step_scale(all_predictors()) |> \n",
    "    step_center(all_predictors())\n",
    "cleveland_recipe\n",
    "\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |> \n",
    "    set_engine(\"kknn\") |> \n",
    "    set_mode(\"classification\")\n",
    "knn_tune\n",
    "\n",
    "cleveland_vfold <- vfold_cv(cleveland_training, v = 10, strata = diagnosis)\n",
    "gridvals <- tibble(neighbors = c(1:100))\n",
    "\n",
    "knn_results <- workflow() |> \n",
    "    add_recipe(cleveland_recipe) |>\n",
    "    add_model(knn_tune) |>\n",
    "    tune_grid(resamples = cleveland_vfold, grid = gridvals) |>\n",
    "    collect_metrics() |>\n",
    "    filter(.metric == \"accuracy\") |>\n",
    "    select(neighbors, mean) |> \n",
    "    arrange(desc(mean))\n",
    "\n",
    "head(knn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10592ca-f59a-4f61-8783-4d4725cec375",
   "metadata": {},
   "source": [
    "*table 6*\n",
    "\n",
    "It seems that our best k-value is going to be k = 45 or k = 46 which both give around 62% accuracy. We will plot a line graph of accuracy vs k to find out which one is better. The accuracy of our predictors may not be the best. This will unfortunately affect our analysis because 62% accuracy is quite low. It means that the predictors that we chose are bad to predict the diagnosis of heart disease. This could just be due to a small sample size of around 227. If we had more data we could more accurately assess our predictors. However, since our predictors aren't too good, our final analysis may be a little off. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a7a0f-1969-47a6-a633-56270de5ee94",
   "metadata": {},
   "source": [
    "**Accuracy Visualization**\n",
    "\n",
    "We can view which k value is better by using a geom_line plot to see how big of a difference in accuracy there is between the k values 45 and 46. We plot the accuracy vs the neighbors to achieve this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0724a-9d98-4935-a031-f5657e12bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "accuracy_plot <- ggplot(knn_results, aes(x = neighbors, y = mean)) + \n",
    "    geom_line() + \n",
    "    labs(x = \"K Values\" , y = \"Accuracy\", title = \"Accuracy for k-values\") + \n",
    "    scale_x_continuous(breaks = seq(0,100, by = 5))\n",
    "accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02241f6-ec4a-4325-95eb-bc40b5c8a381",
   "metadata": {},
   "source": [
    "*figure 4*\n",
    "\n",
    "Based on the graph above, it seems that k = 45 and 46 are both very valid but 46 is a better value for k because the drops on both sides are more similar than on 45. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146550d-9201-4c61-a168-a1ff4f58f6da",
   "metadata": {},
   "source": [
    "**Major Classifier Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2af30-6e93-410d-8500-9fe1e5d16347",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "cleveland_proportions <- cleveland_training |>\n",
    "    group_by(diagnosis) |>\n",
    "    summarize(n = n()) |>\n",
    "    mutate(percent = (100*n) / nrow(cleveland_training))\n",
    "cleveland_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc033cb-20c0-4904-a6b3-6deabeb0bc17",
   "metadata": {},
   "source": [
    "The FALSE diagnosis represents the majority of the training with a value of 54.2% of all results. Our classifier is more accurate than a majority classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a3040-8fcc-4088-8b8c-d4fabc843218",
   "metadata": {},
   "source": [
    "**Fitting the Data**\n",
    "\n",
    "We can now create a working model for our data set with our k value of the best amount of neighborss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f73494-2366-4364-a3ee-c3914f0fb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "fit_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 46) |> \n",
    "    set_engine(\"kknn\") |> \n",
    "    set_mode(\"classification\")\n",
    "\n",
    "fit_model <- workflow() |>\n",
    "    add_recipe(cleveland_recipe) |>\n",
    "    add_model(fit_spec) |>\n",
    "    fit(data = cleveland_training)\n",
    "fit_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e9013-2f36-4913-8d36-9c5af682dc07",
   "metadata": {},
   "source": [
    "**Testing the Classifier**\n",
    "\n",
    "We now use our testing set to look at how our classifier works for our testing data set. We will redict using the same fit as before but this time with the cleveland_testing data set. We need to look at its accuracy and its confusion matrix to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1451d-1933-439c-876e-05fad6e28d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(24)\n",
    "\n",
    "predictions <- predict(fit_model, cleveland_testing) |> \n",
    "    bind_cols(cleveland_testing)\n",
    "\n",
    "metrics <- predictions |> \n",
    "    metrics(truth = diagnosis, estimate = .pred_class) |> \n",
    "    filter(.metric == \"accuracy\")\n",
    "metrics\n",
    "\n",
    "conf_mat <- predictions |> \n",
    "    conf_mat(truth = diagnosis, estimate = .pred_class)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f32d70-d771-4c06-bc9f-03ed91190906",
   "metadata": {},
   "source": [
    "*table 7*\n",
    "\n",
    "Our classifier was actually 63% accurate and labeled 48 out of 76 observations correctly. It also appears that there is an equal probability for our model to overdiagnose (14) and underdiagnose (14). This is good because it shows that our model is not overly biased and gives false observations to one diagnosis over the other one. We can also see that us creating a new diagnosis column instead of the num is a lot better. By aggregating all heart disease severity diagnosis into one diagnosis class, we decrease the chances of misdiagnosis within the subset of patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c48d14-4347-4af8-914f-716604d1fac4",
   "metadata": {},
   "source": [
    "<font size = \"5\"> Discussion </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc56ef-f8f9-4634-9fe1-e3aa398892c2",
   "metadata": {},
   "source": [
    "**Summary and Expected Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be385907-f2ce-43a6-a521-c3a0a40fa2c5",
   "metadata": {},
   "source": [
    "In summary, we have found out that patient diagnosed with heart disease tend to have a higher age, higher cholesterol, and higher resting blood pressure. An article by Hearth Health and Aging also supports this as it states that people over the age of 65 are more prone to heart disease and heart attacks; it also shows that patients without heart disease are the inverse, with lower age, lower cholesterol, and lower resting blood pressure. In our proposal we had initially expected that a higher age, higher cholesterol, and higher resting blood pressure would likely lead to heart disease classification and in our final report we have evidence to support that claim. We expect to find if heart disease can be diagnosed with some common risk factors such as age, serum cholesterol level, and resting blood pressure. Upon completion of this project, we would be able to see the effect of each of the three factors on heart disease; specifically, we could potentially find answers to a variety of questions such as at what age people are more likely to get heart disease, what serum cholesterol level is considered abnormal and therefore can be an indicator of heart disease, or what the resting blood pressure of heart disease patients typically is like. Studies have been shown to support our finding as well through World Health Organization and United Nations as well as a study done by Janosi, Andras. However, it is possible for the three factors picked to be inadequate for identifying heart disease to begin with; in which case, we would have to explore if some other factors would have been better choices. Our classifier's accuracy turned out to be around 60% in accordance with our prediction. This means that it's not really too accurate and can be improved in the future, so there are probably better classifiers out there that better predict heart disease. Our mistakes may have been caused by the fact that the data set we are working on is simply not large enough. There isn't enough data to fully train our classifier and not enough data to test and assess the classifier's accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcaeb6f-d43e-4f1e-8c2c-aa1adc43e406",
   "metadata": {},
   "source": [
    "**Impact of our Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84673e-70f5-44d1-82fb-1a73d1f0231f",
   "metadata": {},
   "source": [
    "Our findings can be used for doctors to diagnose heart disease based on age, cholesterol, and resting blood pressure. Not only would it help doctors reach diagnoses in less time, but it could also provide a second opinion when it comes to identifying false diagnoses. False predictions could also affect the doctor's judgment and thereby give rise to misdiagnoses, so it is fairly important to have a higher level of accuracy. Nonetheless, having this classifier does supply a way for doctors to make decisions and save time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45294a7-b1d1-48d3-bb09-464c321ab4c4",
   "metadata": {},
   "source": [
    "**Future Questions this Could Lead to**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a5ba5-c801-40dd-9134-013b1581ba95",
   "metadata": {},
   "source": [
    "1. How can we improve the accuracy of our classifier?\n",
    "2. Are there better more tell-tale ways to identify heart disease?\n",
    "3. What other factors other than age, cholesterol, and resting blood pressure impact the chance of a person having heart disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd49a6e-0157-4e99-9038-91bd051e573a",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98183bb9-388a-431a-920b-bf70bc70a270",
   "metadata": {},
   "source": [
    "Janosi,Andras, Steinbrunn,William, Pfisterer,Matthias, and Detrano,Robert. (1988). Heart Disease. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X. Finegold, J. A., Asaria, P., & Francis, D. P. (2013). \n",
    "\n",
    "Mortality from ischaemic heart disease by country, region, and age: statistics from World Health Organisation and United Nations. International journal of cardiology, 168(2), 934-945.https://doi.org/10.1016/j.ijcard.2012.10.046 \n",
    "\n",
    "Heart Health and Aging: https://www.nia.nih.gov/health/heart-health/heart-health-and-aging#:~:text=and%20bottom%20chambers.-,How%20Your%20Heart%20Changes%20with%20Age,heart%20disease)%20and%20heart%20failure.\n",
    "\n",
    "Grundy, S. M. (1990). Cholesterol and coronary heart disease: future directions. Jama, 264(23), 3053-3059.\n",
    "\n",
    "Fox, K., Borer, J. S., Camm, A. J., Danchin, N., Ferrari, R., Lopez Sendon, J. L., ... & Heart Rate Working Group. (2007). Resting heart rate in cardiovascular disease. Journal of the American College of Cardiology, 50(9), 823-830."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
